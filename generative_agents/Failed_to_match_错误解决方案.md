# "Failed to match llm output" é”™è¯¯è§£å†³æ–¹æ¡ˆ

## ğŸ” é”™è¯¯åŸå› åˆ†æ

### é—®é¢˜æœ¬è´¨
LLMï¼ˆå¦‚Qwen3ï¼‰çš„è¾“å‡ºæ ¼å¼ä¸ä»£ç é¢„æœŸçš„æ­£åˆ™è¡¨è¾¾å¼ä¸åŒ¹é…ã€‚

### å¸¸è§åŸå› 

1. **LLMè¾“å‡ºäº†é¢å¤–è§£é‡Š**
   ```
   é¢„æœŸ: "æ˜¯"
   å®é™…: "æ˜¯çš„ï¼Œæˆ‘è®¤ä¸ºä»–ä»¬åº”è¯¥å¯¹è¯ã€‚"
   ç»“æœ: âŒ åŒ¹é…å¤±è´¥
   ```

2. **æ ¼å¼ä¸å®Œå…¨ç¬¦åˆ**
   ```
   é¢„æœŸ: "6:00"
   å®é™…: "å¤§çº¦6ç‚¹"
   ç»“æœ: âŒ åŒ¹é…å¤±è´¥
   ```

3. **æ¨¡å‹ç†è§£åå·®**
   ```
   é¢„æœŸ: "yes" æˆ– "no"
   å®é™…: "Maybe" æˆ– "It depends"
   ç»“æœ: âŒ åŒ¹é…å¤±è´¥
   ```

---

## âœ… å·²å®æ–½çš„ä¿®å¤

### 1. å¢å¼ºé”™è¯¯æ—¥å¿— ğŸ”§

**ä¿®æ”¹æ–‡ä»¶**: `modules/model/llm_model.py`

**æ”¹è¿›å†…å®¹**:
```python
# åœ¨ parse_llm_output å‡½æ•°å¼€å¤´æ·»åŠ ç©ºå“åº”æ£€æŸ¥
if not response or len(response.strip()) == 0:
    print(f"\nâš ï¸ LLM returned empty response!")
    if not ignore_empty:
        assert False, "LLM returned empty response"
    return [] if mode == "match_all" else None

# åŸæœ‰çš„é”™è¯¯æ—¥å¿—å¢å¼º
if not rets:
    # æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
    print(f"\nâŒ Failed to match llm output!")
    print(f"Patterns: {patterns}")
    print(f"Response (first 500 chars):\n{response[:500]}")
    print(f"Response (last 200 chars):\n{response[-200:]}\n")
```

**æ•ˆæœ**: ç°åœ¨å‡ºé”™æ—¶ä¼šæ˜¾ç¤ºï¼š
- **ç©ºå“åº”è­¦å‘Š**ï¼ˆæ–°å¢ï¼‰
- æœŸæœ›çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
- LLMçš„å®é™…è¾“å‡ºï¼ˆå‰500å­—ç¬¦å’Œå200å­—ç¬¦ï¼‰
- å¸®åŠ©å¿«é€Ÿå®šä½é—®é¢˜

---

### 1.5 æ”¹è¿› Ollama å“åº”å¤„ç† ğŸ”§

**ä¿®æ”¹æ–‡ä»¶**: `modules/model/llm_model.py` çš„ `OllamaLLMModel._completion` æ–¹æ³•

**æ”¹è¿›å†…å®¹**:
```python
def _completion(self, prompt, temperature=0.5):
    try:
        response = self.ollama_chat(messages=messages, temperature=temperature)
        if response and "choices" in response and len(response["choices"]) > 0:
            ret = response["choices"][0]["message"]["content"]
            ret = re.sub(r"<think>.*</think>", "", ret, flags=re.DOTALL)
            if not ret or len(ret.strip()) == 0:
                print(f"âš ï¸ Ollama returned empty content for model {self._model}")
            return ret
        else:
            print(f"âš ï¸ Ollama response format error: {response}")
            return ""
    except Exception as e:
        print(f"âš ï¸ Ollama request failed: {e}")
        return ""
```

**æ•ˆæœ**:
- âœ… æ£€æµ‹ç©ºå“åº”å¹¶æ‰“å°è­¦å‘Š
- âœ… æ•è·è¯·æ±‚å¼‚å¸¸
- âœ… æ˜¾ç¤ºæ ¼å¼é”™è¯¯è¯¦æƒ…

---

### 2. æ”¹è¿› decide_chat åˆ¤æ–­é€»è¾‘ â­

**ä¿®æ”¹æ–‡ä»¶**: `modules/prompt/scratch.py` çš„ `prompt_decide_chat` æ–¹æ³•

**ä¼˜åŒ–å‰**:
```python
def _callback(response):
    if "No" in response or "no" in response or "å¦" in response or "ä¸" in response:
        return False
    return True
```
**é—®é¢˜**: å¤ªä¸¥æ ¼ï¼Œåªæ£€æŸ¥4ä¸ªè¯

**ä¼˜åŒ–å**:
```python
def _callback(response):
    response_lower = response.lower()
    # æ›´å…¨é¢çš„å¦å®šåˆ¤æ–­
    negative_words = ["no", "å¦", "ä¸", "æ²¡æœ‰", "ä¸ä¼š", "ä¸æƒ³", "ä¸åº”è¯¥", "ä¸å¤ª", "false"]
    for word in negative_words:
        if word in response_lower:
            return False
    # è‚¯å®šåˆ¤æ–­
    positive_words = ["yes", "æ˜¯", "å¯ä»¥", "ä¼š", "åº”è¯¥", "true", "å¥½"]
    for word in positive_words:
        if word in response_lower:
            return True
    # é»˜è®¤è¿”å›Trueï¼ˆé¼“åŠ±å¯¹è¯ï¼‰
    return True
```

**æ”¹è¿›ç‚¹**:
- âœ… æ”¯æŒæ›´å¤šå¦å®šè¯æ±‡
- âœ… æ”¯æŒæ›´å¤šè‚¯å®šè¯æ±‡
- âœ… ä¸åŒºåˆ†å¤§å°å†™
- âœ… é»˜è®¤è¿”å›Trueï¼Œé¼“åŠ±å¯¹è¯ï¼ˆç¬¦åˆå®éªŒç›®æ ‡ï¼‰

---

### 3. å¢åŠ æ‰€æœ‰è°ƒåº¦ç›¸å…³å›è°ƒçš„å®¹é”™ â°

**ä¿®æ”¹æ–‡ä»¶**: `modules/prompt/scratch.py`

#### 3.1 schedule_init (åˆå§‹åŒ–æ—¥ç¨‹)
```python
def _callback(response):
    # å¤„ç†ç©ºå“åº”
    if not response or len(response.strip()) == 0:
        print(f"âš ï¸ schedule_init got empty response, using failsafe")
        return failsafe
    
    try:
        result = parse_llm_output(response, patterns, mode="match_all")
        if not result:
            print(f"âš ï¸ schedule_init no matches found, using failsafe")
            return failsafe
        return result
    except Exception as e:
        print(f"âš ï¸ schedule_init parsing error: {e}, using failsafe")
        return failsafe
```

#### 3.2 schedule_daily (æ¯æ—¥æ—¥ç¨‹)
```python
def _callback(response):
    # å¤„ç†ç©ºå“åº”
    if not response or len(response.strip()) == 0:
        print(f"âš ï¸ schedule_daily got empty response, using failsafe")
        return failsafe
    
    try:
        outputs = parse_llm_output(response, patterns, mode="match_all")
        if not outputs or len(outputs) < 5:
            print(f"âš ï¸ schedule_daily got {len(outputs)} schedules (need >=5), using failsafe")
            return failsafe
        return {s[0]: s[1] for s in outputs}
    except Exception as e:
        print(f"âš ï¸ schedule_daily parsing error: {e}, using failsafe")
        return failsafe
```

#### 3.3 schedule_decompose (åˆ†è§£è®¡åˆ’) - **æœ¬æ¬¡é”™è¯¯çš„æ¥æº**
```python
def _callback(response):
    # å¤„ç†ç©ºå“åº”
    if not response or len(response.strip()) == 0:
        print(f"âš ï¸ schedule_decompose got empty response, using failsafe")
        return [(plan["describe"], 10) for _ in range(int(plan["duration"] / 10))]
    
    try:
        schedules = parse_llm_output(response, patterns, mode="match_all")
        if not schedules:  # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•å†…å®¹
            print(f"âš ï¸ schedule_decompose no matches found, using failsafe")
            return [(plan["describe"], 10) for _ in range(int(plan["duration"] / 10))]
        
        schedules = [(s[0].strip("."), int(s[1])) for s in schedules]
        left = plan["duration"] - sum([s[1] for s in schedules])
        if left > 0:
            schedules.append((plan["describe"], left))
        return schedules
    except Exception as e:
        print(f"âš ï¸ schedule_decompose parsing error: {e}, using failsafe")
        return [(plan["describe"], 10) for _ in range(int(plan["duration"] / 10))]
```

#### 3.4 schedule_revise (ä¿®è®¢è®¡åˆ’)
```python
def _callback(response):
    # å¤„ç†ç©ºå“åº”
    if not response or len(response.strip()) == 0:
        print(f"âš ï¸ schedule_revise got empty response, using failsafe")
        return plan["decompose"]
    
    try:
        schedules = parse_llm_output(response, patterns, mode="match_all")
        if not schedules:
            print(f"âš ï¸ schedule_revise no matches found, using failsafe")
            return plan["decompose"]
        
        decompose = []
        for start, end, describe in schedules:
            m_start = utils.daily_duration(utils.to_date(start, "%H:%M"))
            m_end = utils.daily_duration(utils.to_date(end, "%H:%M"))
            decompose.append({
                "idx": len(decompose),
                "describe": describe,
                "start": m_start,
                "duration": m_end - m_start,
            })
        return decompose
    except Exception as e:
        print(f"âš ï¸ schedule_revise parsing error: {e}, using failsafe")
        return plan["decompose"]
```

**æ”¹è¿›ç‚¹**:
- âœ… æ‰€æœ‰è°ƒåº¦ç›¸å…³å›è°ƒéƒ½æ£€æŸ¥ç©ºå“åº”
- âœ… æ‰€æœ‰å›è°ƒéƒ½æœ‰ try-except ä¿æŠ¤
- âœ… å¤±è´¥æ—¶è‡ªåŠ¨ä½¿ç”¨ failsafe é»˜è®¤å€¼
- âœ… æ‰“å°æ¸…æ™°çš„è­¦å‘Šä¿¡æ¯ï¼Œä¾¿äºè°ƒè¯•
- âœ… **schedule_decompose æ˜¯æœ¬æ¬¡æŠ¥é”™çš„ç›´æ¥åŸå› ï¼Œå·²ä¿®å¤**

---

## ğŸ§ª è¯Šæ–­å·¥å…·

### ä½¿ç”¨ test_llm_format.py æµ‹è¯•æ¨¡å‹è¾“å‡º

```bash
cd C:\Users\admin\Desktop\GenerativeAgentsCN-main\generative_agents
python test_llm_format.py
```

**åŠŸèƒ½**:
- æµ‹è¯•æ¨¡å‹æ˜¯å¦èƒ½æ­£ç¡®å“åº”ç®€å•æ˜¯éé—®é¢˜
- æµ‹è¯•æ—¶é—´æ ¼å¼è¾“å‡º
- æµ‹è¯•è‹±æ–‡/ä¸­æ–‡è¾“å‡º
- æ˜¾ç¤ºå®é™…è¾“å‡ºä¸é¢„æœŸå¯¹æ¯”

**ç¤ºä¾‹è¾“å‡º**:
```
ğŸ” å¼€å§‹æµ‹è¯• Ollama æ¨¡å‹è¾“å‡ºæ ¼å¼
æ¨¡å‹: qwen3:8b-q4_K_M
åœ°å€: http://127.0.0.1:11434/v1
============================================================

ã€æµ‹è¯• 1ã€‘ç®€å•æ˜¯éåˆ¤æ–­
æç¤ºè¯: è¯·å›ç­”ï¼šä»Šå¤©æ˜¯æ˜ŸæœŸå…­å—ï¼Ÿåªç”¨'æ˜¯'æˆ–'å¦'å›ç­”ã€‚...
âœ… æ¨¡å‹è¾“å‡º: 'æ˜¯'
é¢„æœŸæ ¼å¼: ['æ˜¯', 'å¦']

ã€æµ‹è¯• 2ã€‘æ—¶é—´æ ¼å¼è¾“å‡º
æç¤ºè¯: é€šå¸¸äººä»¬æ—©ä¸Š6ç‚¹å·¦å³é†’æ¥...
âœ… æ¨¡å‹è¾“å‡º: '6:00'
é¢„æœŸæ ¼å¼: ['æ•°å­—:æ•°å­—æ ¼å¼']
```

---

## ğŸš€ é‡æ–°å¯åŠ¨å®éªŒ

ä¿®å¤åï¼Œé‡æ–°å¯åŠ¨å®éªŒï¼š

```bash
cd C:\Users\admin\Desktop\GenerativeAgentsCN-main\generative_agents
conda activate generative_agents_cn

# å¯åŠ¨æ–°å®éªŒ
python start.py --name social-freq-v2 --step 40 --stride 3 --verbose info
```

---

## ğŸ“Š å¦‚ä½•ç›‘æ§é”™è¯¯

### æ–¹æ³•1: æŸ¥çœ‹å®æ—¶æ—¥å¿—

```bash
# åœ¨è¿è¡Œä¸­çš„ç»ˆç«¯æŸ¥çœ‹è¾“å‡º
# å¦‚æœçœ‹åˆ° "âŒ Failed to match llm output!" 
# ä¸‹é¢ä¼šæ˜¾ç¤ºå…·ä½“çš„è¾“å‡ºå†…å®¹
```

### æ–¹æ³•2: æ£€æŸ¥æ—¥å¿—æ–‡ä»¶

```bash
# å¦‚æœæŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶
Get-Content results\checkpoints\social-freq-v2\experiment.log | Select-String "Failed"
```

### æ–¹æ³•3: æ£€æµ‹ç‰¹å®špromptå¤±è´¥

å¦‚æœæŸä¸ªç‰¹å®špromptæŒç»­å¤±è´¥ï¼Œå¯ä»¥æ·»åŠ æ›´è¯¦ç»†çš„æ—¥å¿—ï¼š

```python
# åœ¨ modules/prompt/scratch.py çš„ç›¸å…³æ–¹æ³•ä¸­æ·»åŠ 
print(f"ğŸ” è°ƒç”¨ prompt_xxxï¼Œè¾“å…¥å‚æ•°: ...")
```

---

## ğŸ”§ å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: ä»ç„¶å‡ºç° "Failed to match" é”™è¯¯

**æ£€æŸ¥æ­¥éª¤**:

1. **è¿è¡Œè¯Šæ–­å·¥å…·**
   ```bash
   python test_llm_format.py
   ```

2. **æŸ¥çœ‹å®é™…è¾“å‡º**
   é”™è¯¯ä¿¡æ¯ä¼šæ˜¾ç¤ºLLMçš„å®é™…è¾“å‡ºï¼Œæ£€æŸ¥æ˜¯å¦ï¼š
   - åŒ…å«é¢å¤–è§£é‡Š
   - æ ¼å¼ä¸æ ‡å‡†
   - åŒ…å«ç‰¹æ®Šå­—ç¬¦

3. **ä¸´æ—¶ç»•è¿‡ç‰¹å®šprompt**
   å¦‚æœæŸä¸ªpromptæŒç»­å¤±è´¥ï¼Œå¯ä»¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç è¿”å›å€¼ï¼š
   ```python
   def _callback(response):
       return True  # ä¸´æ—¶å¼ºåˆ¶è¿”å›True
   ```

---

### Q2: decide_chat æ€»æ˜¯è¿”å› False

**åŸå› **: LLMè¾“å‡ºäº†å¦å®šè¯

**è§£å†³**:
- âœ… å·²ä¿®æ”¹ä¸ºæ›´å®½å®¹çš„åˆ¤æ–­é€»è¾‘
- âœ… é»˜è®¤è¿”å›Trueé¼“åŠ±å¯¹è¯
- âœ… æ”¯æŒæ›´å¤šè‚¯å®š/å¦å®šå…³é”®è¯

å¦‚æœè¿˜æ˜¯å¤ªä¿å®ˆï¼Œå¯ä»¥ç›´æ¥å¼ºåˆ¶è¿”å›Trueï¼š
```python
def _callback(response):
    return True  # å¼ºåˆ¶æ€»æ˜¯å¯¹è¯
```

---

### Q3: æ¨¡å‹å“åº”å¤ªæ…¢æˆ–è¶…æ—¶

**è§£å†³æ–¹æ¡ˆ**:

1. **æ£€æŸ¥OllamaæœåŠ¡**
   ```bash
   ollama list
   ```

2. **å°è¯•æ›´å°çš„æ¨¡å‹**
   ```bash
   ollama pull qwen2.5:7b
   ```
   
   ç„¶åä¿®æ”¹ `data/config.json`:
   ```json
   {
     "model": "qwen2.5:7b"
   }
   ```

3. **å¢åŠ è¶…æ—¶æ—¶é—´**
   ä¿®æ”¹ `modules/model/llm_model.py` ä¸­çš„è¯·æ±‚å‚æ•°

---

### Q4: æƒ³è¦æ›´æ¿€è¿›çš„å¯¹è¯é¢‘ç‡

å¦‚æœä¿®å¤åå¯¹è¯ä»ç„¶ä¸å¤Ÿé¢‘ç¹ï¼Œå¯ä»¥ï¼š

**é€‰é¡¹1: å¼ºåˆ¶decide_chatæ€»æ˜¯è¿”å›True**
```python
# modules/prompt/scratch.py line ~520
def _callback(response):
    return True  # æ— æ¡ä»¶å¯¹è¯
```

**é€‰é¡¹2: é™ä½å¯¹è¯é—´éš”åˆ°1åˆ†é’Ÿ**
```python
# modules/agent.py line ~547
if delta < 1:  # 1åˆ†é’Ÿé—´éš”
    return False
```

**é€‰é¡¹3: ä½¿ç”¨party_chat.pyå¼ºåˆ¶æ¨¡å¼**
```bash
python party_chat.py --name forced --rounds 100
```

---

## ğŸ“Š é¢„æœŸæ•ˆæœ

ä¿®å¤åï¼Œå®éªŒåº”è¯¥èƒ½å¤Ÿï¼š

1. âœ… **æ­£å¸¸è¿è¡Œ**ï¼šä¸å†é¢‘ç¹å‡ºç° "Failed to match" é”™è¯¯
2. âœ… **æ›´å¤šå¯¹è¯**ï¼šdecide_chatæ›´å®¹æ˜“è¿”å›True
3. âœ… **æ›´å¥½çš„å®¹é”™**ï¼šå³ä½¿LLMè¾“å‡ºç•¥æœ‰åå·®ä¹Ÿèƒ½æ­£å¸¸è§£æ
4. âœ… **è¯¦ç»†æ—¥å¿—**ï¼šå‡ºé”™æ—¶èƒ½çœ‹åˆ°å…·ä½“æ˜¯å“ªé‡Œå‡ºé—®é¢˜
5. âœ… **ç©ºå“åº”å¤„ç†**ï¼šLLMè¿”å›ç©ºå“åº”æ—¶è‡ªåŠ¨ä½¿ç”¨failsafeï¼Œä¸ä¼šå´©æºƒ
6. âœ… **æ‰€æœ‰è°ƒåº¦å‡½æ•°ä¿æŠ¤**ï¼šschedule_init/daily/decompose/revise éƒ½æœ‰å®Œæ•´å®¹é”™

---

## ğŸ” æœ¬æ¬¡é”™è¯¯åˆ†æ

**å…·ä½“é”™è¯¯**:
```
âŒ Failed to match llm output!
Patterns: ['\\d{1,2}\\) .*\\*è®¡åˆ’\\* (.*)[\\(ï¼ˆ]+è€—æ—¶[:ï¼š ]+(\\d{1,2})[,ï¼Œ ]+å‰©ä½™[:ï¼š ]+\\d*[\\)ï¼‰]']
Response (first 500 chars):

Response (last 200 chars):

```

**é—®é¢˜æ‰€åœ¨**: 
- å‡½æ•°ï¼š`prompt_schedule_decompose` (åˆ†è§£è®¡åˆ’ä¸ºå­ä»»åŠ¡)
- åŸå› ï¼šOllama/Qwen3 è¿”å›äº†å®Œå…¨ç©ºçš„å“åº”
- åæœï¼š`parse_llm_output` æ— æ³•åŒ¹é…ä»»ä½•å†…å®¹ï¼Œè§¦å‘ assert å¯¼è‡´ç¨‹åºå´©æºƒ

**æ ¹æœ¬åŸå› å¯èƒ½æ˜¯**:
1. Ollama æœåŠ¡å‹åŠ›è¿‡å¤§ï¼Œè¶…æ—¶æ²¡æœ‰è¿”å›
2. æ¨¡å‹å¯¹æŸä¸ªç‰¹å®š prompt æ— æ³•ç†è§£
3. ç½‘ç»œæˆ–ç³»ç»Ÿèµ„æºé—®é¢˜

**ä¿®å¤æ–¹å¼**:
- âœ… åœ¨ `parse_llm_output` å…¥å£æ·»åŠ ç©ºå“åº”æ£€æŸ¥
- âœ… åœ¨ `schedule_decompose` å›è°ƒä¸­æ·»åŠ ç©ºå“åº”å’Œå¼‚å¸¸å¤„ç†
- âœ… å¤±è´¥æ—¶è¿”å› failsafe é»˜è®¤å€¼è€Œä¸æ˜¯å´©æºƒ
- âœ… Ollama å±‚é¢ä¹Ÿæ·»åŠ ç©ºå“åº”æ£€æµ‹å’Œè­¦å‘Š

---

## ğŸ¯ æµ‹è¯•æ¸…å•

ä¿®å¤åæµ‹è¯•ï¼š

- [ ] è¿è¡Œ `python test_llm_format.py` æ£€æŸ¥æ¨¡å‹è¾“å‡º
- [ ] å¯åŠ¨æ–°å®éªŒ `python start.py --name test-fix --step 10 --stride 5`
- [ ] è§‚å¯Ÿå‰10æ­¥æ˜¯å¦æœ‰é”™è¯¯è¾“å‡º
- [ ] æ£€æŸ¥ `conversation.json` æ˜¯å¦æœ‰å¯¹è¯è®°å½•
- [ ] å¦‚æœä»æœ‰é—®é¢˜ï¼ŒæŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯ä¸­çš„LLMå®é™…è¾“å‡º

---

## ğŸ’¡ æœ€ä½³å®è·µ

1. **å¯åŠ¨å‰å…ˆæµ‹è¯•**
   ```bash
   python test_llm_format.py
   ```

2. **ä½¿ç”¨verboseæ¨¡å¼**
   ```bash
   python start.py --name xxx --verbose info
   ```

3. **å°æ­¥æµ‹è¯•**
   å…ˆè¿è¡Œ10-20æ­¥çœ‹æ˜¯å¦æ­£å¸¸ï¼Œå†è¿è¡Œå®Œæ•´å®éªŒ

4. **ä¿ç•™æ—¥å¿—**
   å‡ºé”™æ—¶çš„è¯¦ç»†è¾“å‡ºå¾ˆé‡è¦ï¼Œå¯ä»¥å¸®åŠ©è¿›ä¸€æ­¥ä¼˜åŒ–

---

## ğŸ“ æ€»ç»“

**æ ¹æœ¬åŸå› **: LLMè¾“å‡ºæ ¼å¼ä¸ä»£ç é¢„æœŸä¸åŒ¹é…

**è§£å†³æ–¹æ¡ˆ**:
1. âœ… å¢å¼ºé”™è¯¯æ—¥å¿—ï¼Œæ˜¾ç¤ºå®é™…è¾“å‡º
2. âœ… æ”¹è¿›callbackå‡½æ•°ï¼Œå¢åŠ å®¹é”™æ€§
3. âœ… é»˜è®¤å€¼ç­–ç•¥ï¼Œå¤±è´¥æ—¶è¿”å›åˆç†é»˜è®¤å€¼
4. âœ… æ›´å®½æ¾çš„åŒ¹é…é€»è¾‘

**æ•ˆæœ**: ä»é¢‘ç¹æŠ¥é”™ â†’ ç¨³å®šè¿è¡Œï¼Œå¯¹è¯é¢‘ç‡æå‡

ç°åœ¨å¯ä»¥é‡æ–°å¯åŠ¨å®éªŒäº†ï¼ğŸš€
