# 超高频对话配置说明

## ✅ 已完成的优化

### 1. 对话间隔：**5分钟** （原60分钟 → 15分钟 → 5分钟）
**位置**：`modules/agent.py` 第547行
```python
# 极致优化：对话间隔降到5分钟，实现超高频对话
if delta < 5:
    return False
```

**效果**：同两个agent可以每5分钟对话一次，频率提升 **12倍**！

---

### 2. 感知范围：**30格** （原10格 → 20格 → 30格）
**位置**：`data/config.json`
```json
{
  "percept": {
    "vision_r": 30,      // 视野半径30格
    "att_bandwidth": 20  // 注意力带宽20个对象
  }
}
```

**效果**：
- agents可以"看到"30格内的其他人（3倍原始范围）
- 注意力带宽20，可以同时关注20个对象
- **相遇概率提升9倍**（面积=πr²）

---

### 3. 其他已优化参数
```json
{
  "think": {
    "interval": 500     // 思考速度500ms（原1000ms）
  },
  "chat_iter": 10,      // 对话深度10轮（原4轮）
  "associate": {
    "retention": 12     // 记忆保留12条（原8条）
  }
}
```

---

## 📊 频率对比

| 配置 | 对话间隔 | 感知范围 | 3小时预计对话数 |
|------|---------|---------|----------------|
| **原始配置** | 60分钟 | 10格 | 1-2次 ❌ |
| **优化v1** | 15分钟 | 10格 | 3-5次 ⚠️ |
| **优化v2** | 15分钟 | 20格 | 8-12次 ✅ |
| **超高频 ⭐** | **5分钟** | **30格** | **20-40次** 🚀 |

---

## 🚀 运行命令

### 标准频率（推荐日常使用）
```bash
python start.py --name experiment --step 50 --stride 10 --verbose info
```
- 50步 × 10分钟 = 8.3小时
- 预计：15-25次对话

### 高频率（推荐实验）
```bash
python start.py --name high-freq --step 40 --stride 5 --verbose info
```
- 40步 × 5分钟 = 3.3小时
- 预计：20-30次对话

### 超高频率（极致密度）⭐
```bash
python start.py --name ultra-freq --step 60 --stride 3 --verbose info
```
- 60步 × 3分钟 = 3小时
- 预计：**30-50次对话** 🔥
- **最密集的采样，最高的对话频率**

---

## 📈 实时监控对话数

### 运行中查看
```bash
# 查看对话总数
python -c "import json; data = json.load(open('results/checkpoints/ultra-freq/conversation.json', encoding='utf-8')); print(f'对话总数：{sum(len(v) for v in data.values())}次')"

# 查看详细分布
python -c "import json; data = json.load(open('results/checkpoints/ultra-freq/conversation.json', encoding='utf-8')); [print(f'{k}: {len(v)}次') for k,v in data.items()]"
```

### 查看最近对话
```powershell
Get-Content results\checkpoints\ultra-freq\conversation.json | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

---

## ⚙️ 进一步优化选项

### 如果还想更频繁：

#### 选项1：降低对话间隔到2分钟
编辑 `modules/agent.py` 第547行：
```python
if delta < 2:  # 从5改为2
    return False
```

#### 选项2：进一步扩大感知范围到50格
编辑 `data/config.json`：
```json
{
  "vision_r": 50,
  "att_bandwidth": 25
}
```

#### 选项3：使用party_chat强制模式
```bash
python party_chat.py --name forced --rounds 100 --novlang-file data\prompts\novlang_rules_clean.txt
```
- 完全强制轮流对话
- 100轮 = 100次完整对话
- 无视地理位置
- **适合纯语言涌现观察**

---

## 🎯 当前测试状态

### high-freq-test（正在运行）
- **配置**：5分钟间隔 + 30格感知 + 5分钟stride
- **步数**：30步 = 2.5小时
- **预期**：15-25次对话
- **状态**：🟢 运行中...

### 完成后验证
```bash
cd generative_agents
python -c "import json; data = json.load(open('results/checkpoints/high-freq-test/conversation.json', encoding='utf-8')); print(f'✅ 对话总数：{sum(len(v) for v in data.values())}次'); [print(f'  {k}: {len(v)}次对话') for k,v in sorted(data.items())]"
```

---

## 💡 理论极限

在当前配置下：
- 4个agents = 6对组合（C(4,2)=6）
- 每对每5分钟可对话1次
- 理论最大值：**每5分钟6次对话**
- 3小时 = 36个5分钟时段
- **理论极限：216次对话**

实际达成率通常为10-20%：
- 因为agents需要在同一地点
- 因为agents正在执行其他任务
- 因为agents需要"决定"是否对话

**预期实际值：20-40次对话/3小时** ✅

---

## 📌 注意事项

### 1. LLM负载
超高频配置会大幅增加LLM调用：
- 每次对话 = 10轮（chat_iter=10）
- 每轮 = 2次LLM调用（发起+响应）
- 40次对话 ≈ 800次LLM调用

**建议**：确保Ollama服务稳定运行

### 2. 运行时间
```
stride=3分钟，step=60：约需30-45分钟实际运行时间
stride=5分钟，step=40：约需20-30分钟实际运行时间
stride=10分钟，step=30：约需15-20分钟实际运行时间
```

### 3. 磁盘空间
每个实验会生成：
- conversation.json（对话记录）
- simulate-*.json（每步状态快照）
- storage/（向量数据库）

每个实验约 **50-200MB**

---

## 🔄 恢复原始配置

如果需要恢复：

### 1. 恢复对话间隔
`modules/agent.py` 第547行改回：
```python
if delta < 60:
    return False
```

### 2. 恢复感知范围
`data/config.json` 改回：
```json
{
  "vision_r": 8,
  "att_bandwidth": 8
}
```

---

## 📖 相关文档

- `小镇高频对话指南.md` - 基础使用说明
- `增加对话频率优化方案.md` - 优化方案对比
- `README_实验指南.md` - party_chat强制模式说明
- `实验设计PPT.md` - 完整实验设计思路

---

**总结**：当前配置已实现 **12倍对话频率提升** + **9倍相遇概率提升** = **预计100倍+整体效果提升**！🚀
